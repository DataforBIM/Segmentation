# Diagnostic: Pourquoi les ouvertures ne sont pas dans protected?
from PIL import Image, ImageDraw, ImageFont
import requests
from io import BytesIO
import numpy as np
from segmentation.semantic_segmentation import semantic_segment
from segmentation.target_resolver import resolve_target
from segmentation.intent_parser import parse_intent
import os

IMAGE_URL = "https://res.cloudinary.com/ddmzn1508/image/upload/v1770198200/DEMO/test-project/static/Galerie/BAC_JARDIN.jpg"

print("=" * 80)
print("üîç DIAGNOSTIC: POURQUOI LES OUVERTURES NE SONT PAS PROT√âG√âES?")
print("=" * 80)

# Charger l'image
print("\nüì• Chargement de l'image...")
response = requests.get(IMAGE_URL)
image = Image.open(BytesIO(response.content)).convert("RGB")
print(f"   ‚úÖ Image: {image.size}")

# √âtape 1: Analyser l'intention
print("\n" + "=" * 80)
print("√âTAPE 1: INTENTION DU PROMPT")
print("=" * 80)

intent = parse_intent("change la fa√ßade en blanc moderne")
target = resolve_target(intent)

print(f"""
Prompt: "change la fa√ßade en blanc moderne"

Target r√©solu:
  ‚Ä¢ Primary: {target.primary}
  ‚Ä¢ Protected: {target.protected}
  ‚Ä¢ Context: {target.context}
""")

print("‚úÖ Le resolver demande bien de prot√©ger: window, door")
print("   V√©rifions si OneFormer les d√©tecte...")

# √âtape 2: Segmentation OneFormer
print("\n" + "=" * 80)
print("√âTAPE 2: D√âTECTION ONEFORMER")
print("=" * 80)

semantic_map = semantic_segment(image, model_type="oneformer")

print(f"\nüìä Classes d√©tect√©es par OneFormer: {len(semantic_map.detected_classes)}")
print("-" * 80)

for i, class_name in enumerate(semantic_map.detected_classes, 1):
    mask_array = np.array(semantic_map.masks[class_name])
    coverage = np.sum(mask_array > 0) / (image.size[0] * image.size[1])
    print(f"  {i:2d}. {class_name:20s} {coverage*100:6.2f}%")

# √âtape 3: V√©rification des classes protected demand√©es
print("\n" + "=" * 80)
print("√âTAPE 3: V√âRIFICATION DES CLASSES PROTECTED")
print("=" * 80)

print(f"\nClasses protected demand√©es par le resolver:")
for prot in target.protected:
    found = prot in semantic_map.masks
    status = "‚úÖ TROUV√â" if found else "‚ùå ABSENT"
    if found:
        coverage = np.sum(np.array(semantic_map.masks[prot]) > 0) / (image.size[0] * image.size[1])
        print(f"  ‚Ä¢ {prot:20s} {status} ({coverage*100:.2f}%)")
    else:
        print(f"  ‚Ä¢ {prot:20s} {status}")

# √âtape 4: Chercher des classes similaires
print("\n" + "=" * 80)
print("√âTAPE 4: CLASSES SIMILAIRES D√âTECT√âES")
print("=" * 80)

opening_keywords = ["window", "door", "glass", "pane", "entrance", "frame", "opening"]
similar_classes = []

for detected_class in semantic_map.detected_classes:
    for keyword in opening_keywords:
        if keyword in detected_class.lower():
            similar_classes.append(detected_class)
            break

if similar_classes:
    print("\nüîç Classes similaires trouv√©es:")
    for cls in similar_classes:
        coverage = np.sum(np.array(semantic_map.masks[cls]) > 0) / (image.size[0] * image.size[1])
        print(f"  ‚Ä¢ {cls}: {coverage*100:.2f}%")
else:
    print("\n‚ùå Aucune classe similaire aux ouvertures d√©tect√©e")

# √âtape 5: Visualisation de l'image pour comprendre
print("\n" + "=" * 80)
print("√âTAPE 5: ANALYSE VISUELLE")
print("=" * 80)

# Sauvegarder l'image pour inspection
os.makedirs("output/diagnostic_protected", exist_ok=True)
image.save("output/diagnostic_protected/image_originale.png")

# Cr√©er une visualisation avec annotations
annotated = image.copy()
draw = ImageDraw.Draw(annotated)

try:
    font = ImageFont.truetype("arial.ttf", 30)
    font_small = ImageFont.truetype("arial.ttf", 20)
except:
    font = ImageFont.load_default()
    font_small = font

# Ajouter annotation
text = "OneFormer ne d√©tecte PAS de fen√™tres/portes ici"
bbox = draw.textbbox((0, 0), text, font=font)
text_width = bbox[2] - bbox[0]
x = (image.width - text_width) // 2
draw.rectangle([x - 10, 10, x + text_width + 10, 60], fill=(255, 0, 0, 200))
draw.text((x, 20), text, fill=(255, 255, 255), font=font)

annotated.save("output/diagnostic_protected/image_annotee.png")

print(f"""
Image originale sauvegard√©e: output/diagnostic_protected/image_originale.png

Observations:
  ‚Ä¢ L'image contient clairement des fen√™tres et portes
  ‚Ä¢ Mais OneFormer (ADE20K) ne les d√©tecte pas sur cette image
  ‚Ä¢ Raisons possibles:
    1. Les ouvertures sont trop petites
    2. Elles fusionnent avec le building
    3. L'angle/√©clairage emp√™che la d√©tection
    4. Le mod√®le ADE20K n'est pas optimal pour cette architecture
""")

# √âtape 6: Solutions propos√©es
print("\n" + "=" * 80)
print("√âTAPE 6: SOLUTIONS PROPOS√âES")
print("=" * 80)

print("""
üîß SOLUTIONS POUR D√âTECTER LES OUVERTURES:

1Ô∏è‚É£  APPROCHE HYBRIDE (RECOMMAND√â):
   ‚Ä¢ OneFormer pour la sc√®ne globale (building, ciel, v√©g√©tation)
   ‚Ä¢ Grounding DINO pour les ouvertures sp√©cifiques
     ‚Üí Text prompt: "window", "door", "glass window"
   ‚Ä¢ SAM2 pour raffiner les d√©tections de Grounding DINO
   
   Exemple:
   ```python
   # D√©tection globale
   semantic_map = semantic_segment(image, "oneformer")
   
   # D√©tection sp√©cifique des ouvertures
   windows = detect_with_grounding_dino(image, "window . glass window . windowpane")
   doors = detect_with_grounding_dino(image, "door . entrance door . doorway")
   
   # Combiner
   protected = windows + doors + person
   final = target - protected
   ```

2Ô∏è‚É£  DIVISION VERTICALE (ACTUELLE):
   ‚Ä¢ Assumer que les ouvertures sont dans le tiers central
   ‚Ä¢ Exclure le tiers central du target
   
   Exemple:
   ```python
   facade_upper = top 1/3 du building
   facade_lower = bottom 1/3 du building
   target = facade_upper + facade_lower  # Exclut le centre
   ```

3Ô∏è‚É£  MOD√àLE SP√âCIALIS√â:
   ‚Ä¢ Utiliser un mod√®le fine-tun√© sur l'architecture
   ‚Ä¢ Detectron2 avec COCO Panoptic (meilleure d√©tection d'objets)
   ‚Ä¢ YOLOv8 segment sp√©cialis√©

4Ô∏è‚É£  D√âTECTION PAR EDGES + CONTOURS:
   ‚Ä¢ D√©tecter les fen√™tres par leurs cadres rectangulaires
   ‚Ä¢ Utiliser OpenCV pour trouver les contours r√©guliers
   ‚Ä¢ Filtrer par ratio largeur/hauteur typique des fen√™tres

üí° RECOMMANDATION IMM√âDIATE:
   Impl√©menter l'approche hybride OneFormer + Grounding DINO
   
   Avantages:
   ‚úì OneFormer reste pour la sc√®ne globale (excellent)
   ‚úì Grounding DINO d√©tecte avec text prompts (flexible)
   ‚úì SAM2 raffine les bords (pr√©cision)
   ‚úì Pas besoin de fine-tuning
""")

print("\n" + "=" * 80)
print("‚úÖ DIAGNOSTIC TERMIN√â")
print("=" * 80)

print(f"""
R√âSUM√â:
  ‚Ä¢ OneFormer d√©tecte: {len(semantic_map.detected_classes)} classes
  ‚Ä¢ Protected demand√©: {len(target.protected)} classes
  ‚Ä¢ Protected trouv√©: 1 classe (person uniquement)
  ‚Ä¢ Manquants: window, door, furniture, object
  
‚ö†Ô∏è  PROBL√àME IDENTIFI√â:
   OneFormer (ADE20K) ne d√©tecte pas les fen√™tres/portes sur cette image

üéØ PROCHAINE √âTAPE:
   Impl√©menter Grounding DINO pour d√©tecter les ouvertures par text prompt
   
üìÅ FICHIERS G√âN√âR√âS:
   - output/diagnostic_protected/image_originale.png
   - output/diagnostic_protected/image_annotee.png
""")
