# Orchestration centrale
from PIL import Image
from config.settings import *
from models.blip import detect_scene_type
from steps.step1_load import load_image
from steps.step2_preprocess import compute_output_size
from steps.step4_upscale import upscale_image
from steps.step5_upload import upload_to_cloudinary


def run_pipeline(
    image_url: str, 
    user_prompt: str,
    # Contr√¥le des √©tapes du pipeline
    enable_scene_detection: bool = True,
    enable_controlnet: bool = True,
    enable_segmentation: bool = True,  # NOUVELLE: Segmentation SAM2
    enable_sdxl: bool = False,
    enable_refiner: bool = False,
    enable_upscaler: bool = False,
    enable_upload: bool = False,
    # Options de segmentation
    segment_target: str = "auto",  # "auto" = d√©tection automatique depuis le prompt
    segment_method: str = "auto"
) -> dict:
    """
    Pipeline complet de g√©n√©ration d'images architecturales
    
    Args:
        image_url: URL de l'image d'entr√©e (Cloudinary)
        user_prompt: Prompt utilisateur
        enable_scene_detection: Activer la d√©tection de sc√®ne BLIP
        enable_controlnet: Activer ControlNet (Canny/Depth)
        enable_segmentation: Activer la segmentation SAM2/SegFormer
        enable_sdxl: Activer la g√©n√©ration SDXL
        enable_refiner: Activer le refiner SDXL
        enable_upscaler: Activer l'upscaling Real-ESRGAN
        enable_upload: Activer l'upload vers Cloudinary
        segment_target: Cible de segmentation ("floor", "wall", etc.)
        segment_method: M√©thode ("auto", "points", "box")
    
    Returns:
        Dict avec l'image finale et les m√©tadonn√©es
    """
    
    print("="*60)
    print("üöÄ D√âMARRAGE DU PIPELINE")
    print("="*60)
    
    # √âtape 1: Chargement
    print("\nüì• √âtape 1: Chargement de l'image")
    current_image = load_image(image_url)
    last_step = "load"
    
    # √âtape 2: D√©tection de sc√®ne
    scene_type = "EXTERIOR"  # Valeur par d√©faut
    if enable_scene_detection:
        print("\nüß† √âtape 2: D√©tection de sc√®ne")
        scene_type = detect_scene_type(current_image)
        print(f"   üéØ Sc√®ne d√©tect√©e: {scene_type}")
    else:
        print("\n‚è≠Ô∏è  √âtape 2: D√©tection de sc√®ne d√©sactiv√©e (utilisation: EXTERIOR)")
    
    # √âtape 3: Pr√©traitement
    print("\nüé® √âtape 3: Pr√©traitement")
    width, height = compute_output_size(current_image, MAX_SIZE)
    print(f"   üìê Dimensions: {width}x{height}")
    
    control_images = {}
    if enable_controlnet:
        from steps.step2_preprocess import make_canny, make_depth, make_openpose, make_normal
        
        # G√©n√©rer tous les pass de ControlNet
        print("   üé® G√©n√©ration de tous les pass ControlNet...")
        
        # Pass 1: Canny (contours) - Tr√®s soft pour sc√®nes a√©riennes
        try:
            if scene_type == "AERIAL":
                # Canny tr√®s soft pour pr√©server les d√©tails fins en a√©rien
                control_images["canny"] = make_canny(current_image, save_path="output/controlnet_canny.png", low_threshold=30, high_threshold=80)
            else:
                # Canny normal pour autres sc√®nes
                control_images["canny"] = make_canny(current_image, save_path="output/controlnet_canny.png")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Erreur Canny: {e}")
        
        # Pass 2: Depth (profondeur)
        try:
            control_images["depth"] = make_depth(current_image, save_path="output/controlnet_depth.png")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Erreur Depth: {e}")
        
        # Pass 3: OpenPose (poses) - Skip for AERIAL scenes
        if scene_type != "AERIAL":
            try:
                control_images["openpose"] = make_openpose(current_image, save_path="output/controlnet_openpose.png")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Erreur OpenPose: {e}")
        else:
            print(f"   ‚è≠Ô∏è  OpenPose d√©sactiv√© pour sc√®nes a√©riennes")
        
        # Pass 4: Normal (normales) - Skip for AERIAL scenes
        if scene_type != "AERIAL":
            try:
                control_images["normal"] = make_normal(current_image, save_path="output/controlnet_normal.png")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Erreur Normal: {e}")
        else:
            print(f"   ‚è≠Ô∏è  Normal map d√©sactiv√©e pour sc√®nes a√©riennes")
        
        print(f"   ‚úÖ {len(control_images)} pass ControlNet g√©n√©r√©s")
    else:
        print("   ‚è≠Ô∏è  ControlNet d√©sactiv√©")
    
    # √âtape 4: Segmentation SAM2/SegFormer (NOUVELLE)
    mask = None
    aerial_elements = None  # Pour stocker les √©l√©ments d√©tect√©s en mode a√©rien
    
    if enable_segmentation and USE_SEGMENTATION:
        print("\nüß† √âtape 4: Segmentation SAM2/SegFormer")
        from steps.step2b_segment import segment_target_region, create_masked_image, load_aerial_metadata
        from prompts.target_detection import detect_segment_target, get_target_description
        
        # D√©tection automatique de la cible si n√©cessaire
        if segment_target == "auto":
            # Passer la sc√®ne d√©tect√©e pour un meilleur filtrage
            segment_target = detect_segment_target(user_prompt, scene_type=scene_type)
            print(f"   üéØ Cible d√©tect√©e automatiquement: {get_target_description(segment_target)}")
        else:
            print(f"   üéØ Cible sp√©cifi√©e manuellement: {get_target_description(segment_target)}")
        
        mask = segment_target_region(
            image=current_image,
            target=segment_target,
            method=segment_method,
            scene_type=scene_type,  # Passer la sc√®ne d√©tect√©e
            dilate=SEGMENT_DILATE,
            feather=SEGMENT_FEATHER,
            save_path="output/segmentation_mask.png"
        )
        
        # Pour les sc√®nes a√©riennes, charger les m√©tadonn√©es des √©l√©ments d√©tect√©s
        if scene_type == "AERIAL":
            aerial_elements = load_aerial_metadata("output/segmentation_mask.png")
            if aerial_elements:
                print(f"   ‚úÖ √âl√©ments a√©riens charg√©s: {len(aerial_elements)} types")
        
        # Sauvegarder une preview du masque sur l'image
        create_masked_image(
            current_image, 
            mask, 
            save_path="output/segmentation_preview.png"
        )
    else:
        print("\n‚è≠Ô∏è  √âtape 4: Segmentation d√©sactiv√©e")
    
    # √âtape 5 & 6: G√©n√©ration SDXL (Inpainting ou ControlNet)
    if enable_sdxl:
        print("\nüîß √âtape 5: Chargement des mod√®les SDXL")
        
        # Choix du mode: Inpainting (avec masque) ou ControlNet (global)
        if mask is not None and USE_INPAINTING:
            # Mode INPAINTING - Modification cibl√©e
            print("   üéØ Mode: INPAINTING (modification cibl√©e)")
            from models.sdxl import load_sdxl_inpaint
            from steps.step3b_inpaint import generate_with_inpainting
            
            pipe_inpaint, refiner = load_sdxl_inpaint(enable_refiner and USE_REFINER)
            
            print("\nüé≠ √âtape 6: G√©n√©ration SDXL Inpainting")
            
            current_image = generate_with_inpainting(
                image=current_image,
                mask=mask,
                pipe_inpaint=pipe_inpaint,
                refiner=refiner if enable_refiner else None,
                scene_type=scene_type,
                user_prompt=user_prompt,
                width=width,
                height=height,
                seed=SEED,
                aerial_elements=aerial_elements  # Passer les √©l√©ments a√©riens
            )
            
        elif mask is not None:
            # Mode CONTROLNET + FUSION avec masque
            print("   üéØ Mode: CONTROLNET + Fusion masqu√©e")
            from models.sdxl import load_sdxl
            from steps.step3b_inpaint import generate_with_controlnet_inpaint
            
            pipe, refiner = load_sdxl(
                SDXL_MODEL, 
                CONTROLNET_MODEL, 
                enable_refiner and USE_REFINER
            )
            
            print("\nüé≠ √âtape 6: G√©n√©ration ControlNet + Fusion")
            control_img = control_images.get("depth") if control_images else None
            
            current_image = generate_with_controlnet_inpaint(
                image=current_image,
                mask=mask,
                control_image=control_img,
                pipe=pipe,
                refiner=refiner if enable_refiner else None,
                scene_type=scene_type,
                user_prompt=user_prompt,
                width=width,
                height=height,
                seed=SEED,
                aerial_elements=aerial_elements  # Passer les √©l√©ments a√©riens
            )
            
        else:
            # Mode CONTROLNET classique (sans masque)
            print("   üéØ Mode: CONTROLNET classique")
            from models.sdxl import load_sdxl
            from steps.step3_generate import generate_with_sdxl
            
            pipe, refiner = load_sdxl(
                SDXL_MODEL, 
                CONTROLNET_MODEL, 
                enable_refiner and USE_REFINER
            )
            
            print("\nüé≠ √âtape 6: G√©n√©ration SDXL")
            control_img = control_images.get("depth") if control_images else None
            print(f"   üéõÔ∏è  ControlNet utilis√©: {'Depth' if control_img else 'None'}")
            
            current_image = generate_with_sdxl(
                image=current_image,
                control_image=control_img,
                pipe=pipe,
                refiner=refiner if enable_refiner else None,
                scene_type=scene_type,
                user_prompt=user_prompt,
                width=width,
                height=height,
                seed=SEED,
                aerial_elements=aerial_elements  # Passer les √©l√©ments a√©riens
            )
        
        # Mettre √† jour la derni√®re √©tape
        if enable_refiner:
            last_step = "refiner"
        else:
            last_step = "sdxl"
    else:
        print("\n‚è≠Ô∏è  √âtapes 5-6: SDXL d√©sactiv√©")
    
    # √âtape 7: Upscaling
    if enable_upscaler and USE_UPSCALER:
        print("\nüîç √âtape 7: Upscaling Real-ESRGAN")
        from models.upscaler import load_upscaler
        
        upscaler = load_upscaler()
        current_image = upscale_image(current_image, upscaler)
        last_step = "upscaler"
    else:
        print("\n‚è≠Ô∏è  √âtape 7: Upscaling d√©sactiv√©")
    
    # L'image finale est toujours le r√©sultat de la derni√®re √©tape activ√©e
    final_image = current_image
    
    # √âtape 8: Upload Cloudinary
    cloudinary_url = None
    if enable_upload:
        print("\n‚òÅÔ∏è  √âtape 8: Upload vers Cloudinary")
        cloudinary_url = upload_to_cloudinary(
            final_image,
            folder="sdxl_outputs/pipeline"
        )
    else:
        print("\n‚è≠Ô∏è  √âtape 8: Upload Cloudinary d√©sactiv√©")
        # Sauvegarder localement √† la place
        local_path = "output/output_local.png"
        final_image.save(local_path)
        print(f"   üíæ Image sauvegard√©e localement: {local_path}")
    
    print("\n" + "="*60)
    print("‚úÖ PIPELINE TERMIN√â")
    print("="*60)
    print(f"üì∏ Image finale g√©n√©r√©e par: {last_step}")
    if cloudinary_url:
        print(f"üåê URL finale: {cloudinary_url}")
    else:
        print(f"üíæ Fichier local: output_local.png")
    
    return {
        "image": final_image,
        "scene_type": scene_type,
        "mask": mask,
        "cloudinary_url": cloudinary_url,
        "dimensions": final_image.size,
        "last_step_executed": last_step,
        "steps_executed": {
            "scene_detection": enable_scene_detection,
            "controlnet": enable_controlnet,
            "segmentation": enable_segmentation,
            "sdxl": enable_sdxl,
            "refiner": enable_refiner,
            "upscaler": enable_upscaler,
            "upload": enable_upload
        }
    }
