# SDXL + ControlNet + Refiner + Inpainting - Optimis√© RTX 4090 24GB
import torch
from diffusers import (
    StableDiffusionXLControlNetImg2ImgPipeline,
    StableDiffusionXLImg2ImgPipeline,
    StableDiffusionXLInpaintPipeline,
    ControlNetModel
)

def load_sdxl(model_id, controlnet_id, use_refiner):
    """
    Charge SDXL avec ControlNet et optionnellement le Refiner
    Optimis√© pour RTX 4090 24GB
    """
    print("   üîß Chargement de ControlNet...")
    controlnet = ControlNetModel.from_pretrained(
        controlnet_id, 
        torch_dtype=torch.float16
    )

    print("   üé® Chargement de SDXL Base...")
    pipe = StableDiffusionXLControlNetImg2ImgPipeline.from_pretrained(
        model_id,
        controlnet=controlnet,
        torch_dtype=torch.float16,
        variant="fp16",
        use_safetensors=True
    ).to("cuda")

    # Optimisations pour RTX 4090 24GB
    try:
        pipe.enable_xformers_memory_efficient_attention()
        print("   ‚ö° XFormers activ√©")
    except Exception as e:
        print(f"   ‚ö†Ô∏è  XFormers non disponible: {e}")
    
    pipe.enable_vae_slicing()
    pipe.enable_vae_tiling()  # R√©duit l'utilisation VRAM
    
    # Avec 24GB, on peut garder le mod√®le enti√®rement en GPU
    print("   ‚úÖ SDXL Base charg√© et optimis√©")

    refiner = None
    if use_refiner:
        print("   ‚ú® Chargement du Refiner...")
        refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(
            "stabilityai/stable-diffusion-xl-refiner-1.0",
            torch_dtype=torch.float16,
            variant="fp16",
            use_safetensors=True
        ).to("cuda")
        
        # Optimisations pour le refiner
        try:
            refiner.enable_xformers_memory_efficient_attention()
        except:
            pass
        refiner.enable_vae_slicing()
        refiner.enable_vae_tiling()
        print("   ‚úÖ Refiner charg√© et optimis√©")

    return pipe, refiner


def load_sdxl_inpaint(use_refiner: bool = True):
    """
    Charge SDXL Inpainting pour la modification cibl√©e avec masque
    Optimis√© pour RTX 4090 24GB
    """
    print("   üñåÔ∏è  Chargement de SDXL Inpainting...")
    
    pipe_inpaint = StableDiffusionXLInpaintPipeline.from_pretrained(
        "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
        torch_dtype=torch.float16,
        variant="fp16",
        use_safetensors=True
    ).to("cuda")
    
    # Optimisations
    try:
        pipe_inpaint.enable_xformers_memory_efficient_attention()
        print("   ‚ö° XFormers activ√© (Inpainting)")
    except Exception as e:
        print(f"   ‚ö†Ô∏è  XFormers non disponible: {e}")
    
    pipe_inpaint.enable_vae_slicing()
    pipe_inpaint.enable_vae_tiling()
    
    print("   ‚úÖ SDXL Inpainting charg√©")
    
    refiner = None
    if use_refiner:
        print("   ‚ú® Chargement du Refiner...")
        refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(
            "stabilityai/stable-diffusion-xl-refiner-1.0",
            torch_dtype=torch.float16,
            variant="fp16",
            use_safetensors=True
        ).to("cuda")
        
        try:
            refiner.enable_xformers_memory_efficient_attention()
        except:
            pass
        refiner.enable_vae_slicing()
        refiner.enable_vae_tiling()
        print("   ‚úÖ Refiner charg√©")
    
    return pipe_inpaint, refiner
