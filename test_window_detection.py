# Test avec dÃ©tection forcÃ©e des fenÃªtres/portes
from PIL import Image
import requests
from io import BytesIO
import numpy as np
from segmentation.semantic_segmentation import semantic_segment, prepare_facade_masks, subtract_masks
import torch

# URL de l'image de test
IMAGE_URL = "https://res.cloudinary.com/ddmzn1508/image/upload/v1770198200/DEMO/test-project/static/Galerie/BAC_JARDIN.jpg"

print("=" * 60)
print("ğŸ” TEST AVEC DÃ‰TECTION FORCÃ‰E DES OUVERTURES")
print("=" * 60)

# Charger l'image
print("\nğŸ“¥ Chargement de l'image...")
response = requests.get(IMAGE_URL)
image = Image.open(BytesIO(response.content)).convert("RGB")
print(f"   âœ… Image chargÃ©e: {image.size}")

# Segmentation OneFormer
print("\nğŸ”· Segmentation OneFormer...")
semantic_map = semantic_segment(image, model_type="oneformer")

print(f"\nğŸ“Š Classes dÃ©tectÃ©es par OneFormer:")
for cls in semantic_map.detected_classes:
    mask = semantic_map.masks[cls]
    coverage = np.sum(np.array(mask) > 0) / (image.size[0] * image.size[1])
    print(f"   - {cls}: {coverage*100:.1f}%")

# VÃ©rifier si des fenÃªtres ont Ã©tÃ© dÃ©tectÃ©es
has_windows = any("window" in cls.lower() for cls in semantic_map.detected_classes)
has_doors = any("door" in cls.lower() for cls in semantic_map.detected_classes)

print(f"\nğŸ” DÃ©tection des ouvertures:")
print(f"   - FenÃªtres dÃ©tectÃ©es: {'âœ…' if has_windows else 'âŒ'}")
print(f"   - Portes dÃ©tectÃ©es: {'âœ…' if has_doors else 'âŒ'}")

if not has_windows and not has_doors:
    print("\nâš ï¸  Aucune ouverture dÃ©tectÃ©e par OneFormer!")
    print("   ğŸ’¡ Solution: Utiliser Grounding DINO pour forcer la dÃ©tection")
    
    # Utiliser Grounding DINO pour dÃ©tecter les fenÃªtres
    print("\nğŸ” DÃ©tection avec Grounding DINO...")
    
    from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection
    
    # Charger Grounding DINO
    processor = AutoProcessor.from_pretrained("IDEA-Research/grounding-dino-base")
    model = AutoModelForZeroShotObjectDetection.from_pretrained(
        "IDEA-Research/grounding-dino-base"
    ).to("cuda")
    
    # DÃ©tecter fenÃªtres et portes
    text = "window. door. glass. windowpane."
    inputs = processor(images=image, text=text, return_tensors="pt").to("cuda")
    
    with torch.no_grad():
        outputs = model(**inputs)
    
    # Post-process
    results = processor.post_process_grounded_object_detection(
        outputs,
        inputs.input_ids,
        box_threshold=0.25,
        text_threshold=0.25,
        target_sizes=[image.size[::-1]]
    )[0]
    
    print(f"   âœ… Grounding DINO: {len(results['boxes'])} dÃ©tections")
    
    # CrÃ©er des masques depuis les boxes dÃ©tectÃ©es
    if len(results['boxes']) > 0:
        windows_mask = Image.new("L", image.size, 0)
        from PIL import ImageDraw
        draw = ImageDraw.Draw(windows_mask)
        
        for box, label, score in zip(results['boxes'], results['labels'], results['scores']):
            if score > 0.3:
                x1, y1, x2, y2 = box.cpu().numpy()
                # Dilater lÃ©gÃ¨rement la box pour avoir une marge
                margin = 5
                draw.rectangle(
                    [x1-margin, y1-margin, x2+margin, y2+margin],
                    fill=255
                )
                print(f"      - {label}: score={score:.2f}, box=[{x1:.0f},{y1:.0f},{x2:.0f},{y2:.0f}]")
        
        windows_mask.save("output/facade_separation/windows_grounding_dino.png")
        print(f"\n   ğŸ’¾ Masque fenÃªtres sauvegardÃ© (Grounding DINO)")
        
        # Maintenant soustraire du masque de faÃ§ade
        facade_masks = prepare_facade_masks(semantic_map, image.size)
        
        if facade_masks["facade_full"]:
            facade_clean_manual = subtract_masks(
                facade_masks["facade_full"],
                [windows_mask]
            )
            
            facade_clean_manual.save("output/facade_separation/facade_clean_with_grounding_dino.png")
            
            # Statistiques
            full_coverage = np.sum(np.array(facade_masks["facade_full"]) > 0) / (image.size[0] * image.size[1])
            clean_coverage = np.sum(np.array(facade_clean_manual) > 0) / (image.size[0] * image.size[1])
            windows_coverage = np.sum(np.array(windows_mask) > 0) / (image.size[0] * image.size[1])
            
            print(f"\nğŸ“Š RÃ©sultats avec Grounding DINO:")
            print(f"   - FaÃ§ade complÃ¨te: {full_coverage*100:.1f}%")
            print(f"   - FenÃªtres dÃ©tectÃ©es: {windows_coverage*100:.1f}%")
            print(f"   - FaÃ§ade nettoyÃ©e: {clean_coverage*100:.1f}%")
            print(f"   - DiffÃ©rence: {(full_coverage - clean_coverage)*100:.1f}%")
            
            if full_coverage > clean_coverage:
                print(f"\nâœ… Protection rÃ©ussie! {(full_coverage - clean_coverage)*100:.1f}% de fenÃªtres retirÃ©es")
            else:
                print(f"\nâš ï¸  Pas de diffÃ©rence - les fenÃªtres n'ont pas Ã©tÃ© dÃ©tectÃ©es")

else:
    print(f"\nâœ… Ouvertures dÃ©tectÃ©es par OneFormer")
    facade_masks = prepare_facade_masks(semantic_map, image.size)

print("\n" + "=" * 60)
print("ğŸ“ CONCLUSION")
print("=" * 60)
print("""
OneFormer seul n'a pas dÃ©tectÃ© les fenÃªtres dans cette image.

Solutions possibles:
1. âœ… Utiliser Grounding DINO en complÃ©ment (dÃ©tection par texte)
2. âœ… Utiliser SAM2 sur les rectangles suspects
3. âœ… Post-processing gÃ©omÃ©trique (dÃ©tecter rectangles dans la faÃ§ade)
4. Fine-tuner OneFormer sur un dataset architectural

ğŸ‘‰ Le systÃ¨me de soustraction fonctionne, mais dÃ©pend de la qualitÃ©
   de la dÃ©tection initiale des fenÃªtres/portes.
""")
